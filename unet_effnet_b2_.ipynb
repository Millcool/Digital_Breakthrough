{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. # üõ† Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:02:59.041627Z",
     "iopub.status.busy": "2022-07-17T13:02:59.040680Z",
     "iopub.status.idle": "2022-07-17T13:02:59.070911Z",
     "shell.execute_reply": "2022-07-17T13:02:59.069821Z",
     "shell.execute_reply.started": "2022-07-17T13:02:59.041567Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "#!pip install --user numpy \n",
    "#!pip install --user pandas \n",
    "#!pip install  segmentation-models-pytorch\n",
    "# !python -m pip install opencv-python\n",
    "# !pip install tensorflow\n",
    "# !pip install -q scikit-learn==1.0\n",
    "#!pip install plotly\n",
    "# !pip install --user albumentations\n",
    "# import sys  \n",
    "# !{sys.executable} -m pip install --user matplotlib\n",
    "#!pip install ipywidgets --user\n",
    "#!pip install -U albumentations[imgaug]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Kaggle !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:02:59.132274Z",
     "iopub.status.busy": "2022-07-17T13:02:59.131736Z",
     "iopub.status.idle": "2022-07-17T13:03:13.221715Z",
     "shell.execute_reply": "2022-07-17T13:03:13.220633Z",
     "shell.execute_reply.started": "2022-07-17T13:02:59.132233Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install  segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Import Libraries  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:13.225777Z",
     "iopub.status.busy": "2022-07-17T13:03:13.225469Z",
     "iopub.status.idle": "2022-07-17T13:03:13.261547Z",
     "shell.execute_reply": "2022-07-17T13:03:13.259921Z",
     "shell.execute_reply.started": "2022-07-17T13:03:13.225747Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:13.263832Z",
     "iopub.status.busy": "2022-07-17T13:03:13.263514Z",
     "iopub.status.idle": "2022-07-17T13:03:24.347770Z",
     "shell.execute_reply": "2022-07-17T13:03:24.346731Z",
     "shell.execute_reply.started": "2022-07-17T13:03:13.263798Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from IPython import display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# gc\n",
    "import gc\n",
    "\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.351435Z",
     "iopub.status.busy": "2022-07-17T13:03:24.350767Z",
     "iopub.status.idle": "2022-07-17T13:03:24.414539Z",
     "shell.execute_reply": "2022-07-17T13:03:24.413751Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.351393Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.416705Z",
     "iopub.status.busy": "2022-07-17T13:03:24.416113Z",
     "iopub.status.idle": "2022-07-17T13:03:24.484802Z",
     "shell.execute_reply": "2022-07-17T13:03:24.483857Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.416668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version1.11.0+cu113\n",
      "The scikit-learn version is 1.0.2.\n",
      "Python version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch version{torch.__version__}')\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "import platform\n",
    "print(f\"Python version: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.490433Z",
     "iopub.status.busy": "2022-07-17T13:03:24.486253Z",
     "iopub.status.idle": "2022-07-17T13:03:24.618772Z",
     "shell.execute_reply": "2022-07-17T13:03:24.617703Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.490403Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    JUST_PREDICT  = False\n",
    "    Kaggle        = False \n",
    "    DEBUG         = False\n",
    "    wandb_on      = False\n",
    "    seed          = 101\n",
    "    MULTIMODEL    = False\n",
    "    weights       = 'imagenet'\n",
    "    backbone      = 'efficientnet-b2'\n",
    "    models        = []\n",
    "    optimizers    = []\n",
    "################################################### \n",
    "    num_of_models = 1\n",
    "    model_number  = 1\n",
    "    train_bs      = 4\n",
    "    valid_bs      = 4\n",
    "    number_imgs   = 100 if DEBUG else 8203     #8203\n",
    "    num_test      = 10 if DEBUG else 1000      # 1000\n",
    "    print_every   = 1  if DEBUG else 100      #500\n",
    "    img_size      = [256, 256] #[540, 960]\n",
    "    start_width   = 512\n",
    "    start_height  = 512\n",
    "    final_width   = 512\n",
    "    final_height  = 512\n",
    "    epochs        = 2  if DEBUG else 80        #35\n",
    "    ###############################################\n",
    "    crop_koef     = 1\n",
    "    lr            = 0.002\n",
    "    num_workers   = 4 if Kaggle else 0\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 0 #1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 4\n",
    "    classes       = [0,6,7,10]\n",
    "    activation    = None #'softmax'\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    images_path   = \"../input/russian-railways-2/images/images/\" if Kaggle else \"../train/images\" \n",
    "    masks_path    = \"../input/russian-railways-2/mask/mask/\" if Kaggle else  \"../train/mask/\"\n",
    "    test_path     = \"../input/russian-railways-2/test/test/\" if Kaggle else \"../test/\"\n",
    "    save_path     = '../working/result/' if Kaggle else \"./result/\"\n",
    "    best_model_w  = '../input/russian-railways-2/best_epoch_ofu-efficientnet-b1_v2.bin' if Kaggle else './last_epoch_ofu-efficientnet-b1_v2.bin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ùó Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.895047Z",
     "iopub.status.busy": "2022-07-17T13:03:24.894758Z",
     "iopub.status.idle": "2022-07-17T13:03:24.959963Z",
     "shell.execute_reply": "2022-07-17T13:03:24.958847Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.895023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.089028Z",
     "iopub.status.busy": "2022-07-17T13:03:25.088702Z",
     "iopub.status.idle": "2022-07-17T13:03:25.151084Z",
     "shell.execute_reply": "2022-07-17T13:03:25.150258Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.088994Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.338708Z",
     "iopub.status.busy": "2022-07-17T13:03:25.338419Z",
     "iopub.status.idle": "2022-07-17T13:03:25.585223Z",
     "shell.execute_reply": "2022-07-17T13:03:25.584267Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.338675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() # gc.collect() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Å–æ–±—Ä–∞–Ω—ã –∏ —É–¥–∞–ª–µ–Ω—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.587313Z",
     "iopub.status.busy": "2022-07-17T13:03:25.586906Z",
     "iopub.status.idle": "2022-07-17T13:03:25.673754Z",
     "shell.execute_reply": "2022-07-17T13:03:25.672836Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.587278Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##################################################################################################################################################################    \n",
    "    \n",
    "##################################################################################################################################################################    \n",
    "def build_model(indx):\n",
    "    if indx == 1: #'model_Unet':\n",
    "        model = smp.Unet(\n",
    "            encoder_name=CFG.backbone,      \n",
    "            encoder_weights=\"imagenet\",     \n",
    "            in_channels=3,                  \n",
    "            classes=CFG.num_classes,       \n",
    "            activation=CFG.activation)\n",
    "    \n",
    "    model.to(CFG.device)\n",
    "    CFG.models = [model]\n",
    "    return  model\n",
    "\n",
    "\n",
    "def load_models(pash):\n",
    "    for model in CFG.models:\n",
    "        model = build_model(model)\n",
    "\n",
    "\n",
    "def load_model(path,indx):\n",
    "    model = build_model(indx)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model.to(CFG.device)\n",
    "    CFG.models = [model]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.675742Z",
     "iopub.status.busy": "2022-07-17T13:03:25.675347Z",
     "iopub.status.idle": "2022-07-17T13:03:25.747429Z",
     "shell.execute_reply": "2022-07-17T13:03:25.746411Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.675704Z"
    }
   },
   "outputs": [],
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel') # Intersection over Union: like dice (index) The Intersection-Over-Union (IoU), also known as the Jaccard Index\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False) # parametrised Jaccard loss || log_loss ‚Äì If True, --> -log(tversky) else 1 - tversky\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.4*BCELoss(y_pred, y_true) + 0.6*TverskyLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÑ Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.749412Z",
     "iopub.status.busy": "2022-07-17T13:03:25.749009Z",
     "iopub.status.idle": "2022-07-17T13:03:25.819925Z",
     "shell.execute_reply": "2022-07-17T13:03:25.818960Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.749374Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch ):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:  \n",
    "    #step = 1\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True): # choose best presition (float32 or float16 for each operation to speed up and best performance)\n",
    "\n",
    "\n",
    "    ###################### FORWARD ######################################################################\n",
    "\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate \n",
    "\n",
    "    ####################### BACKWARD #####################################################################  \n",
    "\n",
    "                # Exits autocast before backward().\n",
    "                # Backward passes under autocast are not recommended.\n",
    "                # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "\n",
    "    ########################################################################################################\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % CFG.n_accumulate == 0: # –æ—Å—Ç–∞—Ç–æ–∫ –æ—Ç –¥–µ–ª–µ–Ω–∏—è —ç—Ç–æ —Å–¥–µ–ª–∞–Ω–æ –≤–µ—Ä–Ω–æ\n",
    "            scaler.step(optimizer) #step - –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad() #zero_grad - –∑–∞–Ω—É–ª–∏—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤ PyTorch –∞–∫–∫—É–º—É–ª–∏—Ä—É—é—Ç—Å—è) \n",
    "\n",
    "            if scheduler is not None: \n",
    "                scheduler.step()      \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "        \n",
    " #########################################################################################################################       \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üëÄ Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.821991Z",
     "iopub.status.busy": "2022-07-17T13:03:25.821725Z",
     "iopub.status.idle": "2022-07-17T13:03:25.890287Z",
     "shell.execute_reply": "2022-07-17T13:03:25.889469Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.821967Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval() # remove dropout, batchnorm # we use it when checking results\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "################## FORWARD ##################################################\n",
    "\n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred) # ?????\n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # returns actual LR\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ Run Training (Training loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.957426Z",
     "iopub.status.busy": "2022-07-17T13:03:25.957148Z",
     "iopub.status.idle": "2022-07-17T13:03:26.028944Z",
     "shell.execute_reply": "2022-07-17T13:03:26.027951Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.957393Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    if CFG.wandb_on:\n",
    "        wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_jaccard   = -np.inf\n",
    "    best_epoch     = -1\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect() # garbage collector - to delete references and objects that not exist any more\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        \n",
    "        #Log the metrics\n",
    "        if CFG.wandb_on:\n",
    "            wandb.log({\"Train Loss\": train_loss, \n",
    "                       \"Valid Loss\": val_loss,\n",
    "                       \"Valid Dice\": val_dice,\n",
    "                       \"Valid Jaccard\": val_jaccard,\n",
    "                        \"LR\": optimizer.param_groups[0]['lr'] # returns actual LRscheduler.get_last_lr()[0]\n",
    "                      })\n",
    "        \n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_dice >= best_dice: \n",
    "            print(f\"{c_}Valid Score  (IOU) ({best_jaccard:0.4f} ---> {val_jaccard:0.4f})\")\n",
    "            print(f\"{c_}Valid Score Improved(DICE) ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            best_dice    = val_dice\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch   = epoch\n",
    "            if CFG.wandb_on:\n",
    "                run.summary[\"Best Dice\"]    = best_dice\n",
    "                run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "                run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch_of{model.name}_v2.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            if CFG.wandb_on:\n",
    "                wandb.save(PATH)\n",
    "                print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch_of{model.name}_v2.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "            \n",
    "        print(); print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model #, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:26.032757Z",
     "iopub.status.busy": "2022-07-17T13:03:26.031903Z",
     "iopub.status.idle": "2022-07-17T13:03:35.753956Z",
     "shell.execute_reply": "2022-07-17T13:03:35.752779Z",
     "shell.execute_reply.started": "2022-07-17T13:03:26.032716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE TRAIN NEW MODEL u-timm-mobilenetv3_small_minimal_100\n"
     ]
    }
   ],
   "source": [
    "if CFG.JUST_PREDICT:\n",
    "#################################################################################################################################\n",
    "    try:\n",
    "        model = load_model(CFG.best_model_w,1) \n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "        print(f'WE WILL TRAIN TRAINED MODEL: {model.name} !!!')\n",
    "    except Exception:\n",
    "        model = build_model(CFG.model_number)\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "        print(f'WE WILL TRAIN NEW MODEL: {model.name} !!!')\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "else:\n",
    "    model = build_model(CFG.model_number)  \n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "    print(f'WE TRAIN NEW MODEL {model.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.755844Z",
     "iopub.status.busy": "2022-07-17T13:03:35.755433Z",
     "iopub.status.idle": "2022-07-17T13:03:35.830043Z",
     "shell.execute_reply": "2022-07-17T13:03:35.828963Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.755804Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_img(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # or msk=cv2.imread(path, 0)\n",
    "    masks = [(msk == v) for v in CFG.classes]\n",
    "    msk = np.stack(masks, axis=-1).astype('float')\n",
    "    return msk\n",
    "    \n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    \n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"main rails\", \"rails\", \"Trains\", 'Background']\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)\n",
    "\n",
    "def get_preprocessing_test(preprocessing_fn):\n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.833618Z",
     "iopub.status.busy": "2022-07-17T13:03:35.832906Z",
     "iopub.status.idle": "2022-07-17T13:03:35.907571Z",
     "shell.execute_reply": "2022-07-17T13:03:35.906457Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.833557Z"
    }
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "#      \"\"\" Read images, apply augmentation and preprocessing transformations.\n",
    "#     Args:\n",
    "#         images_dir (str): path to images folder\n",
    "#         masks_dir (str): path to segmentation masks folder\n",
    "#         class_values (list): values of classes to extract from segmentation mask\n",
    "#         augmentation (albumentations.Compose): data transfromation pipeline \n",
    "#             (e.g. flip, scale, etc.)\n",
    "#         preprocessing (albumentations.Compose): data preprocessing \n",
    "#             (e.g. noralization, shape manipulation, etc.)\n",
    "\n",
    "    def __init__(self, images_paths, masks_paths = None, label=True, transforms=None,  preprocessing= None):\n",
    "        self.label      = label\n",
    "        self.img_paths  = images_paths\n",
    "        self.msk_paths  = masks_paths\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "        self.preprocessing_img = get_preprocessing_test(preprocessing_fn)\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        \n",
    "        if self.label: # WHEN WE TRAIN \n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            \n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img, msk  = data['image'], data['mask']\n",
    "            if self.preprocessing:\n",
    "                data = self.preprocessing(image=img, mask=msk)\n",
    "                img, msk  = data['image'], data['mask']\n",
    "            return img, msk\n",
    "        else: # WHEN WE PREDICT\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            if self.preprocessing:\n",
    "                data =  self.preprocessing_img(image=img)\n",
    "                img = data['image']\n",
    "            return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.915384Z",
     "iopub.status.busy": "2022-07-17T13:03:35.915117Z",
     "iopub.status.idle": "2022-07-17T13:03:36.035073Z",
     "shell.execute_reply": "2022-07-17T13:03:36.034185Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.915360Z"
    }
   },
   "outputs": [],
   "source": [
    "#A.Sharpen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:36.036884Z",
     "iopub.status.busy": "2022-07-17T13:03:36.036495Z",
     "iopub.status.idle": "2022-07-17T13:03:36.106556Z",
     "shell.execute_reply": "2022-07-17T13:03:36.105628Z",
     "shell.execute_reply.started": "2022-07-17T13:03:36.036846Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "       A.HorizontalFlip(p=0.5),\n",
    "        A.Resize(height=CFG.start_height, width=CFG.start_width, interpolation=cv2.INTER_NEAREST),\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.3, border_mode=0),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                 A.RandomCrop(height=CFG.final_height, width=CFG.final_width, always_apply=True),\n",
    "                 A.CenterCrop(height =CFG.final_height, width =CFG.final_width,p =1.0),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "         ], p=1.0),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(height=CFG.start_height, width=CFG.start_width, interpolation=cv2.INTER_NEAREST),\n",
    "        \n",
    "        ], p=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üç∞ DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:36.108338Z",
     "iopub.status.busy": "2022-07-17T13:03:36.107918Z",
     "iopub.status.idle": "2022-07-17T13:03:36.176616Z",
     "shell.execute_reply": "2022-07-17T13:03:36.175625Z",
     "shell.execute_reply.started": "2022-07-17T13:03:36.108302Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    \n",
    "    img_names= [ os.path.join(CFG.images_path,img_name) for img_name in os.listdir(CFG.images_path)]\n",
    "    masks_names = [ os.path.join(CFG.masks_path,mask_name) for mask_name in os.listdir(CFG.masks_path)]\n",
    "    img_names = img_names[0:CFG.number_imgs]\n",
    "    masks_names=masks_names[0:CFG.number_imgs]\n",
    "    image_train, image_valid, mask_train, mask_valid = train_test_split(img_names, masks_names, test_size=0.2, random_state=CFG.seed)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_dataset = BuildDataset(image_train, mask_train, transforms=data_transforms['train'],preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    valid_dataset = BuildDataset(image_valid, mask_valid, transforms=data_transforms['valid'],preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, \n",
    "                              num_workers=CFG.num_workers, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, \n",
    "                              num_workers=CFG.num_workers, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:37.418831Z",
     "iopub.status.busy": "2022-07-17T13:03:37.418099Z",
     "iopub.status.idle": "2022-07-17T13:03:37.541174Z",
     "shell.execute_reply": "2022-07-17T13:03:37.540163Z",
     "shell.execute_reply.started": "2022-07-17T13:03:37.418796Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:37.542905Z",
     "iopub.status.busy": "2022-07-17T13:03:37.542525Z",
     "iopub.status.idle": "2022-07-17T13:03:49.134106Z",
     "shell.execute_reply": "2022-07-17T13:03:49.132921Z",
     "shell.execute_reply.started": "2022-07-17T13:03:37.542868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 128, 128]), torch.Size([1, 4, 128, 128]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, msks = next(iter(train_loader))\n",
    "imgs.size(), msks.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimiser and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.218506Z",
     "iopub.status.busy": "2022-07-17T13:03:49.217448Z",
     "iopub.status.idle": "2022-07-17T13:03:49.286893Z",
     "shell.execute_reply": "2022-07-17T13:03:49.285954Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.218466Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, ##  <---\n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.356413Z",
     "iopub.status.busy": "2022-07-17T13:03:49.353532Z",
     "iopub.status.idle": "2022-07-17T13:03:49.423352Z",
     "shell.execute_reply": "2022-07-17T13:03:49.422484Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.356386Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizers(number):\n",
    "    if number == 1:\n",
    "        optimizer_1 = optim.Adam(CFG.models[0].parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "        CFG.optimizers = [optimizer_1]\n",
    "    return CFG.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.425106Z",
     "iopub.status.busy": "2022-07-17T13:03:49.424675Z",
     "iopub.status.idle": "2022-07-17T13:03:49.490605Z",
     "shell.execute_reply": "2022-07-17T13:03:49.489623Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.425069Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizers = build_optimizers(1)\n",
    "scheduler =  fetch_scheduler(CFG.optimizers[0])# None # Decrease LR when needed, useless with  Adam (has adaptive LR) optimizer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÖ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.494403Z",
     "iopub.status.busy": "2022-07-17T13:03:49.494044Z",
     "iopub.status.idle": "2022-07-17T13:03:49.557755Z",
     "shell.execute_reply": "2022-07-17T13:03:49.556860Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.494374Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.625389Z",
     "iopub.status.busy": "2022-07-17T13:03:49.625121Z",
     "iopub.status.idle": "2022-07-17T13:03:49.692083Z",
     "shell.execute_reply": "2022-07-17T13:03:49.691074Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.625365Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce GTX 1060 6GB\n",
      "\n",
      "Epoch 1/80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   2%|‚ñé                      | 104/6562 [00:41<43:24,  2.48it/s, gpu_mem=0.11 GB, lr=0.00350, train_loss=0.0186]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m train_loader, valid_loader \u001b[38;5;241m=\u001b[39m prepare_loaders()\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m CFG\u001b[38;5;241m.\u001b[39moptimizers[ind]\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, optimizer, scheduler, device, num_epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect() \u001b[38;5;66;03m# garbage collector - to delete references and objects that not exist any more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m val_loss, val_scores \u001b[38;5;241m=\u001b[39m valid_one_epoch(model, valid_loader, \n\u001b[0;32m     25\u001b[0m                                          device\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m     26\u001b[0m                                          epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m     27\u001b[0m val_dice, val_jaccard \u001b[38;5;241m=\u001b[39m val_scores\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[0;32m      6\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      8\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (images, masks) \u001b[38;5;129;01min\u001b[39;00m pbar:  \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#step = 1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     12\u001b[0m     masks  \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mBuildDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     29\u001b[0m msk \u001b[38;5;241m=\u001b[39m load_msk(msk_path)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 32\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     img, msk  \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessing:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\albumentations\\core\\composition.py:209\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[0;32m    208\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n\u001b[1;32m--> 209\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mCompose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_targets_contiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ensure output targets are contiguous\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    212\u001b[0m     p\u001b[38;5;241m.\u001b[39mpostprocess(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\albumentations\\core\\composition.py:280\u001b[0m, in \u001b[0;36mCompose._make_targets_contiguous\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 280\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     result[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not CFG.JUST_PREDICT:\n",
    "    for ind,  model in enumerate(CFG.models, start=0):\n",
    "        train_loader, valid_loader = prepare_loaders()\n",
    "        optimizer = CFG.optimizers[ind]\n",
    "        model = run_training(model, optimizer, scheduler,\n",
    "                                      device=CFG.device,\n",
    "                                      num_epochs=CFG.epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
