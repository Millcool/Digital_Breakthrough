{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. # üõ† Install Libraries","metadata":{}},{"cell_type":"markdown","source":"## For PC","metadata":{}},{"cell_type":"code","source":"#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n#!pip install --user numpy \n#!pip install --user pandas \n#!pip install  segmentation-models-pytorch\n# !python -m pip install opencv-python\n# !pip install tensorflow\n# !pip install -q scikit-learn==1.0\n#!pip install plotly\n# !pip install --user albumentations\n# import sys  \n# !{sys.executable} -m pip install --user matplotlib\n#!pip install ipywidgets --user\n#!pip install -U albumentations[imgaug]","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:31.815142Z","iopub.execute_input":"2022-07-22T06:44:31.815519Z","iopub.status.idle":"2022-07-22T06:44:31.820625Z","shell.execute_reply.started":"2022-07-22T06:44:31.815487Z","shell.execute_reply":"2022-07-22T06:44:31.819415Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## For Kaggle !!","metadata":{}},{"cell_type":"code","source":"!pip install  segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:31.898691Z","iopub.execute_input":"2022-07-22T06:44:31.899585Z","iopub.status.idle":"2022-07-22T06:44:43.156015Z","shell.execute_reply.started":"2022-07-22T06:44:31.899532Z","shell.execute_reply":"2022-07-22T06:44:43.154768Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# üìö Import Libraries  \n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.options.plotting.backend = \"plotly\"\nimport segmentation_models_pytorch as smp\nimport random\nfrom glob import glob\nimport os, shutil\nfrom tqdm import tqdm\ntqdm.pandas()\nimport time\nimport copy\n#import joblib\n#from collections import defaultdict\nfrom IPython import display as ipd\nfrom PIL import Image\n# visualization\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\n# Sklearn\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\n# PyTorch \nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nc_  = Fore.GREEN\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\n# gc\nimport gc","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-07-22T06:44:43.158596Z","iopub.execute_input":"2022-07-22T06:44:43.159110Z","iopub.status.idle":"2022-07-22T06:44:57.003674Z","shell.execute_reply.started":"2022-07-22T06:44:43.159065Z","shell.execute_reply":"2022-07-22T06:44:57.002409Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## versions","metadata":{}},{"cell_type":"code","source":"print(f'Torch version{torch.__version__}')\nprint('The scikit-learn version is {}.'.format(sklearn.__version__))\nimport platform\nprint(f\"Python version: {platform.python_version()}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.005224Z","iopub.execute_input":"2022-07-22T06:44:57.005621Z","iopub.status.idle":"2022-07-22T06:44:57.013005Z","shell.execute_reply.started":"2022-07-22T06:44:57.005583Z","shell.execute_reply":"2022-07-22T06:44:57.011911Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# ‚öôÔ∏è Configuration ","metadata":{}},{"cell_type":"code","source":"class CFG:\n    JUST_PREDICT  = True\n    Kaggle        = True \n    DEBUG         = False\n    wandb_on      = False\n    seed          = 101\n    MULTIMODEL    = True\n    #exp_name      = 'Baselinev2'\n    #comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n    model_name_1    = 'u-efficientnet-b1'\n    model_name_2    = 'u-efficientnet-b2'\n    model_name_3    = 'u-timm-mobilenetv3_small_minimal_100'\n    weights       = 'imagenet'\n    backbone_1    = 'efficientnet-b1'\n    backbone_2    = 'efficientnet-b2' \n    backbone_3    = 'timm-mobilenetv3_small_minimal_100'\n    backbone_4    = 'efficientnet-b2'\n    models        = []\n    optimizers    = []\n################################################### \n    num_of_models = 4\n    model_number  = 8\n    train_bs      = 12\n    valid_bs      = 12\n    number_imgs   = 100 if DEBUG else 8203     #8203\n    num_test      = 10 if DEBUG else 1000      # 1000\n    print_every   = 8  if DEBUG else 100      #500\n    img_size      = [256, 256] #[540, 960]\n    start_width   = 512\n    start_height  = 512\n    final_width   = 512\n    final_height  = 512\n    epochs        = 4  if DEBUG else 28        #35\n    ###############################################\n    crop_koef     = 1\n    lr            = 2e-3\n    num_workers   = 4 if Kaggle else 0\n    scheduler     = 'CosineAnnealingLR'\n    min_lr        = 1e-6\n    T_max         = int(30000/train_bs*epochs)+50\n    T_0           = 25\n    warmup_epochs = 0\n    wd            = 0 #1e-6\n    n_accumulate  = max(1, 32//train_bs)\n    n_fold        = 5\n    num_classes   = 4\n    classes       = [0,6,7,10]\n    activation    = None #'softmax'\n    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    images_path   = \"../input/russian-railways-2/images/images/\" if Kaggle else \"./train/images/\" #\"../–¶–∏—Ñ—Ä–æ–≤–æ–π –ø—Ä–æ—Ä—ã–≤ 2022_–õ–µ—Ç–æ\\train\\images\"\n    masks_path    = \"../input/russian-railways-2/mask/mask/\" if Kaggle else  \"./train/mask/\"\n    test_path     = \"../input/russian-railways-2/test/test/\" if Kaggle else \"./test/\"\n    save_path     = '../working/result/' if Kaggle else \"./result/\"\n    best_model_w_1= '../input/russian-railways-2/best_epoch_ofu-efficientnet-b1_v2.bin' if Kaggle else './last_epoch_ofu-efficientnet-b1_v2.bin'\n    best_model_w_2= '../input/russian-railways-2/best_epoch_ofu-efficientnet-b2_v2.bin' if Kaggle else './last_epoch_ofu-efficientnet-b2_v2.bin'\n    best_model_w_3= '../input/russian-railways-2/best_epoch_ofu-timm-mobilenetv3_small_minimal_100_v2.bin' if Kaggle else './best_epoch_ofu-timm-mobilenetv3_small_minimal_100_v2.bin'\n    best_model_w_4= '../input/weights'\n    best_model_w_5= None\n    best_model_w_6= None","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.015483Z","iopub.execute_input":"2022-07-22T06:44:57.016380Z","iopub.status.idle":"2022-07-22T06:44:57.044150Z","shell.execute_reply.started":"2022-07-22T06:44:57.016337Z","shell.execute_reply":"2022-07-22T06:44:57.042938Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.046252Z","iopub.execute_input":"2022-07-22T06:44:57.046602Z","iopub.status.idle":"2022-07-22T06:44:57.069599Z","shell.execute_reply.started":"2022-07-22T06:44:57.046571Z","shell.execute_reply":"2022-07-22T06:44:57.068628Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# üìà Visualization","metadata":{}},{"cell_type":"code","source":"def visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.071191Z","iopub.execute_input":"2022-07-22T06:44:57.071635Z","iopub.status.idle":"2022-07-22T06:44:57.083548Z","shell.execute_reply.started":"2022-07-22T06:44:57.071594Z","shell.execute_reply":"2022-07-22T06:44:57.081717Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"gc.collect() # gc.collect() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ —Å–æ–±—Ä–∞–Ω—ã –∏ —É–¥–∞–ª–µ–Ω—ã.","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.086197Z","iopub.execute_input":"2022-07-22T06:44:57.088882Z","iopub.status.idle":"2022-07-22T06:44:57.325336Z","shell.execute_reply.started":"2022-07-22T06:44:57.088825Z","shell.execute_reply":"2022-07-22T06:44:57.323901Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# üì¶ Model\n","metadata":{}},{"cell_type":"code","source":"\nimport segmentation_models_pytorch as smp\n\n\n##################################################################################################################################################################    \n    \n##################################################################################################################################################################    \ndef build_model(indx):\n    if indx == 1: \n        # 7.7 million\n        model = smp.Unet(\n            encoder_name='efficientnet-b1',      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n            classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n            activation=CFG.activation)\n        CFG.backbone = 'efficientnet-b1'\n        \n    elif indx == 2: \n        model = smp.Unet(\n            encoder_name='efficientnet-b2',\n            encoder_weights=\"imagenet\",     \n            in_channels=3,                  \n            classes=CFG.num_classes,       \n            activation=CFG.activation)\n        CFG.backbone = 'efficientnet-b2'\n        \n    elif indx == 3: \n        model = smp.Unet(\n            encoder_name='timm-mobilenetv3_small_minimal_100',      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n            in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n            classes=CFG.num_classes,        # model output channels (number of classes in your dataset)\n            activation=CFG.activation)\n        CFG.backbone = 'timm-mobilenetv3_small_minimal_100'\n    elif indx == 4: \n        model = smp.Unet(\n            encoder_name='efficientnet-b2',\n            encoder_weights=\"imagenet\",     \n            in_channels=3,                  \n            classes=CFG.num_classes,       \n            activation=CFG.activation)\n        CFG.backbone = 'efficientnet-b2'\n    \n    model.to(CFG.device)\n    CFG.models = [model]\n    return  model\n\n\ndef load_models(pash):\n    for model in CFG.models:\n        model = build_model(model)\n\n\ndef load_model(path,indx):\n    model = build_model(indx)\n    model.load_state_dict(torch.load(path , map_location=torch.device('cpu')))\n    model.eval()\n    model.to(CFG.device)\n    CFG.models.append(model)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.327159Z","iopub.execute_input":"2022-07-22T06:44:57.327500Z","iopub.status.idle":"2022-07-22T06:44:57.344331Z","shell.execute_reply.started":"2022-07-22T06:44:57.327470Z","shell.execute_reply":"2022-07-22T06:44:57.342930Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading models !","metadata":{}},{"cell_type":"code","source":"preprocessing_fn =[]\n\nif CFG.JUST_PREDICT:\n    preprocessing_fn.append(None)\n    preprocessing_fn.append(smp.encoders.get_preprocessing_fn(CFG.backbone_1, CFG.weights))\n    preprocessing_fn.append(smp.encoders.get_preprocessing_fn(CFG.backbone_2, CFG.weights))\n    preprocessing_fn.append(smp.encoders.get_preprocessing_fn(CFG.backbone_3, CFG.weights))\n    preprocessing_fn.append(smp.encoders.get_preprocessing_fn(CFG.backbone_4, CFG.weights))\n\nmodel_name = [ 'Nothing','u-efficientnet-b1','u-efficientnet-b2','u-timm-mobilenetv3_small_minimal_100' ,'u-efficientnet-b2' ]\nmodel_path = [0,'../input/russian-railways-2/best_epoch_ofu-efficientnet-b1_v2.bin',\n              '../input/russian-railways-2/best_epoch_ofu-efficientnet-b2_v2.bin',\n              '../input/russian-railways-2/best_epoch_ofu-timm-mobilenetv3_small_minimal_100_v2.bin',\n             '../input/weights/best_epoch_ofu-efficientnet-b2_v2.bin']\nbest_model_w = [0,CFG.best_model_w_1, CFG.best_model_w_2, CFG.best_model_w_3,CFG.best_model_w_4 ]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.345694Z","iopub.execute_input":"2022-07-22T06:44:57.346384Z","iopub.status.idle":"2022-07-22T06:44:57.361780Z","shell.execute_reply.started":"2022-07-22T06:44:57.346346Z","shell.execute_reply":"2022-07-22T06:44:57.360453Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n\ndef load_img(path):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return image\n\ndef load_msk(path):\n    msk = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # or msk=cv2.imread(path, 0)\n    masks = [(msk == v) for v in CFG.classes]\n    msk = np.stack(masks, axis=-1).astype('float')\n    return msk\n        \n    \ndef to_tensor(x, **kwargs):\n    return x.transpose(2, 0, 1).astype('float32')\n\n\ndef get_preprocessing(preprocessing_fn):\n    _transform = [\n        A.Lambda(image=preprocessing_fn),\n        A.Lambda(image=to_tensor, mask=to_tensor),\n    ]\n    return A.Compose(_transform)\n\ndef get_preprocessing_test(preprocessing_fn):\n    _transform = [\n        A.Lambda(image=preprocessing_fn),\n        A.Lambda(image=to_tensor),\n    ]\n    return A.Compose(_transform)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.366493Z","iopub.execute_input":"2022-07-22T06:44:57.367272Z","iopub.status.idle":"2022-07-22T06:44:57.377886Z","shell.execute_reply.started":"2022-07-22T06:44:57.367220Z","shell.execute_reply":"2022-07-22T06:44:57.376667Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# üçö Dataset class\n","metadata":{}},{"cell_type":"code","source":"class BuildDataset(torch.utils.data.Dataset):\n#      \"\"\" Read images, apply augmentation and preprocessing transformations.\n#     Args:\n#         images_dir (str): path to images folder\n#         masks_dir (str): path to segmentation masks folder\n#         class_values (list): values of classes to extract from segmentation mask\n#         augmentation (albumentations.Compose): data transfromation pipeline \n#             (e.g. flip, scale, etc.)\n#         preprocessing (albumentations.Compose): data preprocessing \n#             (e.g. noralization, shape manipulation, etc.) \n\n    def __init__(self, images_paths, masks_paths = None, label=True, transforms=None,  preprocessing= None ,preprocessing_img = None ):\n        self.label      = label\n        self.img_paths  = images_paths\n        self.msk_paths  = masks_paths\n        self.transforms = transforms\n        self.preprocessing = preprocessing\n        self.preprocessing_img = preprocessing_img\n    def __len__(self):\n        return len(self.img_paths)\n    \n    \n    def __getitem__(self, index):\n        img_path  = self.img_paths[index]\n        img = load_img(img_path)\n        \n        if self.label: # WHEN WE TRAIN \n            msk_path = self.msk_paths[index]\n            msk = load_msk(msk_path)\n            \n            if self.transforms:\n                data = self.transforms(image=img, mask=msk)\n                img, msk  = data['image'], data['mask']\n            if self.preprocessing:\n                data = self.preprocessing(image=img, mask=msk)\n                img, msk  = data['image'], data['mask']\n            return img, msk\n        else: # WHEN WE PREDICT\n            if self.transforms:\n                data = self.transforms(image=img)\n                img  = data['image']\n            if self.preprocessing:\n                data =  self.preprocessing_img(image=img)\n                img = data['image']\n            return img    ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.379420Z","iopub.execute_input":"2022-07-22T06:44:57.380538Z","iopub.status.idle":"2022-07-22T06:44:57.394122Z","shell.execute_reply.started":"2022-07-22T06:44:57.380500Z","shell.execute_reply":"2022-07-22T06:44:57.392918Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# üç∞ DataLoader","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.395658Z","iopub.execute_input":"2022-07-22T06:44:57.396052Z","iopub.status.idle":"2022-07-22T06:44:57.412100Z","shell.execute_reply.started":"2022-07-22T06:44:57.396018Z","shell.execute_reply":"2022-07-22T06:44:57.410917Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \n    \"valid\": A.Compose([\n        A.Resize(height=CFG.start_height, width=CFG.start_width, interpolation=cv2.INTER_NEAREST),\n        ], p=1.0)\n\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.413430Z","iopub.execute_input":"2022-07-22T06:44:57.414154Z","iopub.status.idle":"2022-07-22T06:44:57.426178Z","shell.execute_reply.started":"2022-07-22T06:44:57.414116Z","shell.execute_reply":"2022-07-22T06:44:57.424714Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Make a new directory for results !","metadata":{}},{"cell_type":"code","source":"import shutil, os\n\ntry:\n    if CFG.Kaggle:\n        os.mkdir('../working/result')\n        print('KAGGLE DIR CREATED')\n    else:\n        shutil.rmtree('./result')\n        os.mkdir('./result')\n        print('PC DIR CREATED')\nexcept Exception:\n    print(\"DIR NOT CREATED\")\n    pass\n    ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.427681Z","iopub.execute_input":"2022-07-22T06:44:57.428314Z","iopub.status.idle":"2022-07-22T06:44:57.444872Z","shell.execute_reply.started":"2022-07-22T06:44:57.428274Z","shell.execute_reply":"2022-07-22T06:44:57.443525Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# üî≠ Prediction","metadata":{}},{"cell_type":"code","source":"img_names_test= [ os.path.join(CFG.test_path,img_name) for img_name in os.listdir(CFG.test_path)]\nimg_names_test = img_names_test[0:CFG.num_test]\nprint(len(img_names_test))\n# sizes = []\n# for image_file in img_names_test:\n#     img = Image.open(image_file).convert(\"RGB\")\n#     orig_size=img.size\n#     sizes.append(orig_size)\nsizes = [(3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), \n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160),\n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512),\n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512),\n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512),\n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), \n         (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160),\n         (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), \n         (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512),\n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512),\n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512),\n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160),\n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160),\n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160),\n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160),\n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512),\n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160),\n         (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512),\n         (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), \n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512),\n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512),\n         (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512),\n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), \n         (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512),\n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), \n         (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), \n         (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), \n         (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), \n         (2688, 1512), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), \n         (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (2688, 1512), (3840, 2160), \n         (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512),\n         (3840, 2160), (2688, 1512), (2688, 1512), (3840, 2160), (2688, 1512), (2688, 1512), (2688, 1512), (3840, 2160), (3840, 2160), \n         (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), \n         (3840, 2160),(3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160), (3840, 2160), (3840, 2160), (3840, 2160), (2688, 1512), (3840, 2160)]\n\nsave_path = CFG.save_path\npreds = []\n\n\n            ","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.447259Z","iopub.execute_input":"2022-07-22T06:44:57.447913Z","iopub.status.idle":"2022-07-22T06:44:57.766248Z","shell.execute_reply.started":"2022-07-22T06:44:57.447858Z","shell.execute_reply":"2022-07-22T06:44:57.765050Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Color Check","metadata":{}},{"cell_type":"code","source":"###########################################################################################################################\n###########################################################################################################################\n################################################### MULTI MODEL SISTEM ####################################################\n###########################################################################################################################\n###########################################################################################################################\nif CFG.MULTIMODEL:\n    print(\"MULTI_MODEL_MODE\")\n    #for indx, model in enumerate(CFG.models, start=1):\n    for indx in range(4,5):\n        test_dataset = BuildDataset(img_names_test,None, label=False, \n                                    transforms=data_transforms['valid'],\n                                    preprocessing=get_preprocessing(preprocessing_fn[indx]), \n                                    preprocessing_img= get_preprocessing_test(preprocessing_fn[indx]))\n        test_loader  = DataLoader(test_dataset, batch_size=1,  num_workers=CFG.num_workers, shuffle=False, pin_memory=True)\n        data_loader_iter = iter(test_loader)\n\n       \n        print(model_name[indx])\n        model_pred = load_model(model_path[indx],indx)\n        print(f'WE USE TRAINED MODEL ‚Ññ {indx}: {model_pred.name}!!!')\n        model_pred = model_pred.to(CFG.device)\n        for index, imgs in enumerate(test_loader):\n            with torch.no_grad():\n                imgs = imgs.to(CFG.device, dtype=torch.float)\n                pred = model_pred(imgs)\n                pred = nn.Sigmoid()(pred)\n                imgs = next(data_loader_iter)\n                preds.append(pred)\n                #if index % 100 == 0:\n                pred.to(\"cpu\",dtype=torch.float)\n                pred = pred.cpu().detach().numpy()#(\"cpu\")\n                pred_arg_max = np.argmax(pred, axis = 1)\n                print(np.unique(pred_arg_max))\n                pred_arg_max[pred_arg_max == 0 ] = 0\n                pred_arg_max[pred_arg_max == 1 ] = 6\n                pred_arg_max[pred_arg_max == 2 ] = 7\n                pred_arg_max[pred_arg_max == 3 ] = 10\n                res = np.array(pred_arg_max).astype(np.uint8)\n                res = np.reshape(res, (CFG.start_height,CFG.start_width))#(CFG.img_size[0], CFG.img_size[1]))\n                img = Image.fromarray(res)\n                img = img.resize(sizes[index],Image.NEAREST)\n                if index % 200 == 0: #CFG.print_every\n                    imgplot=plt.imshow(img)\n                    plt.show()\n                img.save(save_path + img_names_test[index].split(\"/\")[-1])\n\ngc.collect()\nprint(\"PREDICTONS DONE !\")","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:47:03.209537Z","iopub.execute_input":"2022-07-22T06:47:03.210041Z","iopub.status.idle":"2022-07-22T06:59:44.680351Z","shell.execute_reply.started":"2022-07-22T06:47:03.209990Z","shell.execute_reply":"2022-07-22T06:59:44.678905Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# str = 'img_0.0036494254624107603.png'\n# path_2 = CFG.images_path + str\n# path = CFG.masks_path + str\n# msk = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n# msk = Image.fromarray(msk)\n# imgplot=plt.imshow(msk)\n# plt.show()\n# #####################################################################\n# image = cv2.imread(path_2)\n# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n# data = data_transforms['valid'](image=image)\n# image  = data['image']\n# data =  get_preprocessing_test(preprocessing_fn)(image=image)\n# image = data['image'] \n# image = np.expand_dims(image, axis = 0)\n# image = torch.tensor(image)\n# image = image.to(CFG.device)\n# pred = model_pred(image)\n# pred.to(\"cpu\",dtype=torch.float)\n# pred = pred.cpu().detach().numpy()#(\"cpu\")\n\n# pred_arg_max = np.argmax(pred, axis = 1)\n# # yellow - CLASS 2\n# # yellow - train - 10 - CLASS 2 | more light main rail - 7 - CLASS 3 | SIDE RAIL - 6 - MORE DARK CLASS 1 \\ BACKGROUND - 0 PINK CLASS 0\n# pred_arg_max[pred_arg_max == 0 ] = 0\n# pred_arg_max[pred_arg_max == 1 ] = 6\n# pred_arg_max[pred_arg_max == 2 ] = 7\n# pred_arg_max[pred_arg_max == 3 ] = 10\n# res = np.array(pred_arg_max).astype(np.uint8)\n# res = np.reshape(res, (CFG.start_width,CFG.start_height))#(CFG.img_size[0], CFG.img_size[1]))\n# img = Image.fromarray(res)\n# img = img.resize(sizes[index],Image.NEAREST)\n# #if index % CFG.print_every == 0:\n# imgplot=plt.imshow(img)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T06:44:57.795319Z","iopub.status.idle":"2022-07-22T06:44:57.796002Z","shell.execute_reply.started":"2022-07-22T06:44:57.795608Z","shell.execute_reply":"2022-07-22T06:44:57.795636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ‚úÇÔ∏è Remove Files","metadata":{}},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive('name', 'zip', '../working/result/')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-07-22T07:00:01.984387Z","iopub.execute_input":"2022-07-22T07:00:01.984989Z","iopub.status.idle":"2022-07-22T07:00:02.605307Z","shell.execute_reply.started":"2022-07-22T07:00:01.984930Z","shell.execute_reply":"2022-07-22T07:00:02.604053Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}