{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. # 🛠 Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:02:59.041627Z",
     "iopub.status.busy": "2022-07-17T13:02:59.040680Z",
     "iopub.status.idle": "2022-07-17T13:02:59.070911Z",
     "shell.execute_reply": "2022-07-17T13:02:59.069821Z",
     "shell.execute_reply.started": "2022-07-17T13:02:59.041567Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "#!pip install --user numpy \n",
    "#!pip install --user pandas \n",
    "#!pip install  segmentation-models-pytorch\n",
    "# !python -m pip install opencv-python\n",
    "# !pip install tensorflow\n",
    "# !pip install -q scikit-learn==1.0\n",
    "#!pip install plotly\n",
    "# !pip install --user albumentations\n",
    "# import sys  \n",
    "# !{sys.executable} -m pip install --user matplotlib\n",
    "#!pip install ipywidgets --user\n",
    "#!pip install -U albumentations[imgaug]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Kaggle !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:02:59.132274Z",
     "iopub.status.busy": "2022-07-17T13:02:59.131736Z",
     "iopub.status.idle": "2022-07-17T13:03:13.221715Z",
     "shell.execute_reply": "2022-07-17T13:03:13.220633Z",
     "shell.execute_reply.started": "2022-07-17T13:02:59.132233Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install  segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚 Import Libraries  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:13.225777Z",
     "iopub.status.busy": "2022-07-17T13:03:13.225469Z",
     "iopub.status.idle": "2022-07-17T13:03:13.261547Z",
     "shell.execute_reply": "2022-07-17T13:03:13.259921Z",
     "shell.execute_reply.started": "2022-07-17T13:03:13.225747Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:13.263832Z",
     "iopub.status.busy": "2022-07-17T13:03:13.263514Z",
     "iopub.status.idle": "2022-07-17T13:03:24.347770Z",
     "shell.execute_reply": "2022-07-17T13:03:24.346731Z",
     "shell.execute_reply.started": "2022-07-17T13:03:13.263798Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import segmentation_models_pytorch as smp\n",
    "import random\n",
    "from glob import glob\n",
    "import os, shutil\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from IPython import display as ipd\n",
    "from PIL import Image\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Sklearn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# gc\n",
    "import gc\n",
    "\n",
    "import shutil, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.351435Z",
     "iopub.status.busy": "2022-07-17T13:03:24.350767Z",
     "iopub.status.idle": "2022-07-17T13:03:24.414539Z",
     "shell.execute_reply": "2022-07-17T13:03:24.413751Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.351393Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.416705Z",
     "iopub.status.busy": "2022-07-17T13:03:24.416113Z",
     "iopub.status.idle": "2022-07-17T13:03:24.484802Z",
     "shell.execute_reply": "2022-07-17T13:03:24.483857Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.416668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version1.11.0+cu113\n",
      "The scikit-learn version is 1.0.2.\n",
      "Python version: 3.9.12\n"
     ]
    }
   ],
   "source": [
    "print(f'Torch version{torch.__version__}')\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "import platform\n",
    "print(f\"Python version: {platform.python_version()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.490433Z",
     "iopub.status.busy": "2022-07-17T13:03:24.486253Z",
     "iopub.status.idle": "2022-07-17T13:03:24.618772Z",
     "shell.execute_reply": "2022-07-17T13:03:24.617703Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.490403Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    JUST_PREDICT  = False\n",
    "    Kaggle        = False \n",
    "    DEBUG         = False\n",
    "    wandb_on      = False\n",
    "    seed          = 101\n",
    "    MULTIMODEL    = False\n",
    "    weights       = 'imagenet'\n",
    "    backbone      = 'efficientnet-b1'\n",
    "    models        = []\n",
    "    optimizers    = []\n",
    "################################################### \n",
    "    num_of_models = 1\n",
    "    model_number  = 1\n",
    "    train_bs      = 1\n",
    "    valid_bs      = 1\n",
    "    number_imgs   = 100 if DEBUG else 8203     #8203\n",
    "    num_test      = 10 if DEBUG else 1000      # 1000\n",
    "    print_every   = 1  if DEBUG else 100      #500\n",
    "    img_size      = [256, 256] #[540, 960]\n",
    "    start_width   = 256\n",
    "    start_height  = 256\n",
    "    final_width   = 256\n",
    "    final_height  = 256\n",
    "    epochs        = 2  if DEBUG else 80        #35\n",
    "    ###############################################\n",
    "    crop_koef     = 1\n",
    "    lr            = 0.002\n",
    "    num_workers   = 4 if Kaggle else 0\n",
    "    scheduler     = 'CosineAnnealingLR'\n",
    "    min_lr        = 1e-6\n",
    "    T_max         = int(30000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    warmup_epochs = 0\n",
    "    wd            = 1e-6\n",
    "    n_accumulate  = max(1, 32//train_bs)\n",
    "    n_fold        = 5\n",
    "    num_classes   = 4\n",
    "    classes       = [0,6,7,10]\n",
    "    activation    = None #'softmax'\n",
    "    device        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    images_path   = \"../input/russian-railways-2/images/images/\" if Kaggle else \"../train/images\" \n",
    "    masks_path    = \"../input/russian-railways-2/mask/mask/\" if Kaggle else  \"../train/mask/\"\n",
    "    test_path     = \"../input/russian-railways-2/test/test/\" if Kaggle else \"../test/\"\n",
    "    save_path     = '../working/result/' if Kaggle else \"./result/\"\n",
    "    best_model_w  = '../input/russian-railways-2/best_epoch_ofu-efficientnet-b1_v2.bin' if Kaggle else './last_epoch_ofu-efficientnet-b1_v2.bin'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ❗ Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:24.895047Z",
     "iopub.status.busy": "2022-07-17T13:03:24.894758Z",
     "iopub.status.idle": "2022-07-17T13:03:24.959963Z",
     "shell.execute_reply": "2022-07-17T13:03:24.958847Z",
     "shell.execute_reply.started": "2022-07-17T13:03:24.895023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> SEEDING DONE\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('> SEEDING DONE')\n",
    "    \n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.089028Z",
     "iopub.status.busy": "2022-07-17T13:03:25.088702Z",
     "iopub.status.idle": "2022-07-17T13:03:25.151084Z",
     "shell.execute_reply": "2022-07-17T13:03:25.150258Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.088994Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.338708Z",
     "iopub.status.busy": "2022-07-17T13:03:25.338419Z",
     "iopub.status.idle": "2022-07-17T13:03:25.585223Z",
     "shell.execute_reply": "2022-07-17T13:03:25.584267Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.338675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() # gc.collect() возвращает количество объектов, которые были собраны и удалены."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📦 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.587313Z",
     "iopub.status.busy": "2022-07-17T13:03:25.586906Z",
     "iopub.status.idle": "2022-07-17T13:03:25.673754Z",
     "shell.execute_reply": "2022-07-17T13:03:25.672836Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.587278Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "##################################################################################################################################################################    \n",
    "    \n",
    "##################################################################################################################################################################    \n",
    "def build_model(indx):\n",
    "    if indx == 1: #'model_Unet':\n",
    "        model = smp.Unet(\n",
    "            encoder_name=CFG.backbone,      \n",
    "            encoder_weights=\"imagenet\",     \n",
    "            in_channels=3,                  \n",
    "            classes=CFG.num_classes,       \n",
    "            activation=CFG.activation)\n",
    "    \n",
    "    model.to(CFG.device)\n",
    "    CFG.models = [model]\n",
    "    return  model\n",
    "\n",
    "\n",
    "def load_models(pash):\n",
    "    for model in CFG.models:\n",
    "        model = build_model(model)\n",
    "\n",
    "\n",
    "def load_model(path,indx):\n",
    "    model = build_model(indx)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    model.to(CFG.device)\n",
    "    CFG.models = [model]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔧 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.675742Z",
     "iopub.status.busy": "2022-07-17T13:03:25.675347Z",
     "iopub.status.idle": "2022-07-17T13:03:25.747429Z",
     "shell.execute_reply": "2022-07-17T13:03:25.746411Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.675704Z"
    }
   },
   "outputs": [],
   "source": [
    "JaccardLoss = smp.losses.JaccardLoss(mode='multilabel') # Intersection over Union: like dice (index) The Intersection-Over-Union (IoU), also known as the Jaccard Index\n",
    "DiceLoss    = smp.losses.DiceLoss(mode='multilabel')\n",
    "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
    "TverskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False) # parametrised Jaccard loss || log_loss – If True, --> -log(tversky) else 1 - tversky\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = ((2*inter+epsilon)/(den+epsilon)).mean(dim=(1,0))\n",
    "    return dice\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
    "    y_true = y_true.to(torch.float32)\n",
    "    y_pred = (y_pred>thr).to(torch.float32)\n",
    "    inter = (y_true*y_pred).sum(dim=dim)\n",
    "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
    "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
    "    return iou\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return 0.4*BCELoss(y_pred, y_true) + 0.6*TverskyLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚄 Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.749412Z",
     "iopub.status.busy": "2022-07-17T13:03:25.749009Z",
     "iopub.status.idle": "2022-07-17T13:03:25.819925Z",
     "shell.execute_reply": "2022-07-17T13:03:25.818960Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.749374Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch ):\n",
    "    model.train()\n",
    "    scaler = amp.GradScaler()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "    for step, (images, masks) in pbar:  \n",
    "    #step = 1\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        with amp.autocast(enabled=True): # choose best presition (float32 or float16 for each operation to speed up and best performance)\n",
    "\n",
    "\n",
    "    ###################### FORWARD ######################################################################\n",
    "\n",
    "            y_pred = model(images)\n",
    "            loss   = criterion(y_pred, masks)\n",
    "            loss   = loss / CFG.n_accumulate \n",
    "\n",
    "    ####################### BACKWARD #####################################################################  \n",
    "\n",
    "                # Exits autocast before backward().\n",
    "                # Backward passes under autocast are not recommended.\n",
    "                # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "\n",
    "    ########################################################################################################\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % CFG.n_accumulate == 0: # остаток от деления это сделано верно\n",
    "            scaler.step(optimizer) #step - обновление весов модели\n",
    "            scaler.update()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad() #zero_grad - занулить веса модели (по умолчанию градиенты в PyTorch аккумулируются) \n",
    "\n",
    "            if scheduler is not None: \n",
    "                scheduler.step()      \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_mem=f'{mem:0.2f} GB')\n",
    "        \n",
    " #########################################################################################################################       \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 👀 Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.821991Z",
     "iopub.status.busy": "2022-07-17T13:03:25.821725Z",
     "iopub.status.idle": "2022-07-17T13:03:25.890287Z",
     "shell.execute_reply": "2022-07-17T13:03:25.889469Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.821967Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval() # remove dropout, batchnorm # we use it when checking results\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    val_scores = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "    for step, (images, masks) in pbar:        \n",
    "        images  = images.to(device, dtype=torch.float)\n",
    "        masks   = masks.to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "################## FORWARD ##################################################\n",
    "\n",
    "        y_pred  = model(images)\n",
    "        loss    = criterion(y_pred, masks)\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        \n",
    "        y_pred = nn.Sigmoid()(y_pred) # ?????\n",
    "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
    "        val_scores.append([val_dice, val_jaccard])\n",
    "        \n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        current_lr = optimizer.param_groups[0]['lr'] # returns actual LR\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                        lr=f'{current_lr:0.5f}',\n",
    "                        gpu_memory=f'{mem:0.2f} GB')\n",
    "    val_scores  = np.mean(val_scores, axis=0)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🏃 Run Training (Training loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:25.957426Z",
     "iopub.status.busy": "2022-07-17T13:03:25.957148Z",
     "iopub.status.idle": "2022-07-17T13:03:26.028944Z",
     "shell.execute_reply": "2022-07-17T13:03:26.027951Z",
     "shell.execute_reply.started": "2022-07-17T13:03:25.957393Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    # To automatically log gradients\n",
    "    if CFG.wandb_on:\n",
    "        wandb.watch(model, log_freq=100)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice      = -np.inf\n",
    "    best_jaccard   = -np.inf\n",
    "    best_epoch     = -1\n",
    "    \n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect() # garbage collector - to delete references and objects that not exist any more\n",
    "        \n",
    "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
    "        train_loss = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device=CFG.device, epoch=epoch)\n",
    "        \n",
    "        val_loss, val_scores = valid_one_epoch(model, valid_loader, \n",
    "                                                 device=CFG.device, \n",
    "                                                 epoch=epoch)\n",
    "        val_dice, val_jaccard = val_scores\n",
    "    \n",
    "        \n",
    "        #Log the metrics\n",
    "        if CFG.wandb_on:\n",
    "            wandb.log({\"Train Loss\": train_loss, \n",
    "                       \"Valid Loss\": val_loss,\n",
    "                       \"Valid Dice\": val_dice,\n",
    "                       \"Valid Jaccard\": val_jaccard,\n",
    "                        \"LR\": optimizer.param_groups[0]['lr'] # returns actual LRscheduler.get_last_lr()[0]\n",
    "                      })\n",
    "        \n",
    "        print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
    "        \n",
    "        # deep copy the model\n",
    "        if val_dice >= best_dice: \n",
    "            print(f\"{c_}Valid Score  (IOU) ({best_jaccard:0.4f} ---> {val_jaccard:0.4f})\")\n",
    "            print(f\"{c_}Valid Score Improved(DICE) ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
    "            best_dice    = val_dice\n",
    "            best_jaccard = val_jaccard\n",
    "            best_epoch   = epoch\n",
    "            if CFG.wandb_on:\n",
    "                run.summary[\"Best Dice\"]    = best_dice\n",
    "                run.summary[\"Best Jaccard\"] = best_jaccard\n",
    "                run.summary[\"Best Epoch\"]   = best_epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = f\"best_epoch_of{model.name}_v2.bin\"\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            if CFG.wandb_on:\n",
    "                wandb.save(PATH)\n",
    "                print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        last_model_wts = copy.deepcopy(model.state_dict())\n",
    "        PATH = f\"last_epoch_of{model.name}_v2.bin\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "            \n",
    "        print(); print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model #, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading models !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:26.032757Z",
     "iopub.status.busy": "2022-07-17T13:03:26.031903Z",
     "iopub.status.idle": "2022-07-17T13:03:35.753956Z",
     "shell.execute_reply": "2022-07-17T13:03:35.752779Z",
     "shell.execute_reply.started": "2022-07-17T13:03:26.032716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE TRAIN NEW MODEL u-efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "if CFG.JUST_PREDICT:\n",
    "#################################################################################################################################\n",
    "    try:\n",
    "        model = load_model(CFG.best_model_w,1) \n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "        print(f'WE WILL TRAIN TRAINED MODEL: {model.name} !!!')\n",
    "    except Exception:\n",
    "        model = build_model(CFG.model_number)\n",
    "        preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "        print(f'WE WILL TRAIN NEW MODEL: {model.name} !!!')\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "else:\n",
    "    model = build_model(CFG.model_number)  \n",
    "    preprocessing_fn = smp.encoders.get_preprocessing_fn(CFG.backbone, CFG.weights)\n",
    "    print(f'WE TRAIN NEW MODEL {model.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.755844Z",
     "iopub.status.busy": "2022-07-17T13:03:35.755433Z",
     "iopub.status.idle": "2022-07-17T13:03:35.830043Z",
     "shell.execute_reply": "2022-07-17T13:03:35.828963Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.755804Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_img(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "def load_msk(path):\n",
    "    msk = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # or msk=cv2.imread(path, 0)\n",
    "    masks = [(msk == v) for v in CFG.classes]\n",
    "    msk = np.stack(masks, axis=-1).astype('float')\n",
    "    return msk\n",
    "    \n",
    "def show_img(img, mask=None):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    plt.imshow(img, cmap='bone')\n",
    "    \n",
    "    \n",
    "    if mask is not None:\n",
    "        plt.imshow(mask, alpha=0.5)\n",
    "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
    "        labels = [\"main rails\", \"rails\", \"Trains\", 'Background']\n",
    "        plt.legend(handles,labels)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)\n",
    "\n",
    "def get_preprocessing_test(preprocessing_fn):\n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "        A.Lambda(image=to_tensor),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.833618Z",
     "iopub.status.busy": "2022-07-17T13:03:35.832906Z",
     "iopub.status.idle": "2022-07-17T13:03:35.907571Z",
     "shell.execute_reply": "2022-07-17T13:03:35.906457Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.833557Z"
    }
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "#      \"\"\" Read images, apply augmentation and preprocessing transformations.\n",
    "#     Args:\n",
    "#         images_dir (str): path to images folder\n",
    "#         masks_dir (str): path to segmentation masks folder\n",
    "#         class_values (list): values of classes to extract from segmentation mask\n",
    "#         augmentation (albumentations.Compose): data transfromation pipeline \n",
    "#             (e.g. flip, scale, etc.)\n",
    "#         preprocessing (albumentations.Compose): data preprocessing \n",
    "#             (e.g. noralization, shape manipulation, etc.)\n",
    "\n",
    "    def __init__(self, images_paths, masks_paths = None, label=True, transforms=None,  preprocessing= None):\n",
    "        self.label      = label\n",
    "        self.img_paths  = images_paths\n",
    "        self.msk_paths  = masks_paths\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "        self.preprocessing_img = get_preprocessing_test(preprocessing_fn)\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path  = self.img_paths[index]\n",
    "        img = load_img(img_path)\n",
    "        \n",
    "        if self.label: # WHEN WE TRAIN \n",
    "            msk_path = self.msk_paths[index]\n",
    "            msk = load_msk(msk_path)\n",
    "            \n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img, mask=msk)\n",
    "                img, msk  = data['image'], data['mask']\n",
    "            if self.preprocessing:\n",
    "                data = self.preprocessing(image=img, mask=msk)\n",
    "                img, msk  = data['image'], data['mask']\n",
    "            return img, msk\n",
    "        else: # WHEN WE PREDICT\n",
    "            if self.transforms:\n",
    "                data = self.transforms(image=img)\n",
    "                img  = data['image']\n",
    "            if self.preprocessing:\n",
    "                data =  self.preprocessing_img(image=img)\n",
    "                img = data['image']\n",
    "            return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:35.915384Z",
     "iopub.status.busy": "2022-07-17T13:03:35.915117Z",
     "iopub.status.idle": "2022-07-17T13:03:36.035073Z",
     "shell.execute_reply": "2022-07-17T13:03:36.034185Z",
     "shell.execute_reply.started": "2022-07-17T13:03:35.915360Z"
    }
   },
   "outputs": [],
   "source": [
    "#A.Sharpen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:36.036884Z",
     "iopub.status.busy": "2022-07-17T13:03:36.036495Z",
     "iopub.status.idle": "2022-07-17T13:03:36.106556Z",
     "shell.execute_reply": "2022-07-17T13:03:36.105628Z",
     "shell.execute_reply.started": "2022-07-17T13:03:36.036846Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "       A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Resize(height=CFG.start_height, width=CFG.start_width, interpolation=cv2.INTER_NEAREST),\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.3, border_mode=0),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                 A.RandomCrop(height=CFG.final_height, width=CFG.final_width, always_apply=True),\n",
    "                 A.CenterCrop(height =CFG.final_height, width =CFG.final_width,p =1.0),\n",
    "            ],\n",
    "            p=1.0,\n",
    "        ),\n",
    "     ], p=1.0),\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(height=CFG.start_height, width=CFG.start_width, interpolation=cv2.INTER_NEAREST),\n",
    "        \n",
    "        ], p=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🍰 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:36.108338Z",
     "iopub.status.busy": "2022-07-17T13:03:36.107918Z",
     "iopub.status.idle": "2022-07-17T13:03:36.176616Z",
     "shell.execute_reply": "2022-07-17T13:03:36.175625Z",
     "shell.execute_reply.started": "2022-07-17T13:03:36.108302Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_loaders():\n",
    "    \n",
    "    img_names= [ os.path.join(CFG.images_path,img_name) for img_name in os.listdir(CFG.images_path)]\n",
    "    masks_names = [ os.path.join(CFG.masks_path,mask_name) for mask_name in os.listdir(CFG.masks_path)]\n",
    "    img_names = img_names[0:CFG.number_imgs]\n",
    "    masks_names=masks_names[0:CFG.number_imgs]\n",
    "    image_train, image_valid, mask_train, mask_valid = train_test_split(img_names, masks_names, test_size=0.2, random_state=CFG.seed)\n",
    "\n",
    "    \n",
    "    \n",
    "    train_dataset = BuildDataset(image_train, mask_train, transforms=data_transforms['train'],preprocessing=get_preprocessing(preprocessing_fn))\n",
    "    valid_dataset = BuildDataset(image_valid, mask_valid, transforms=data_transforms['valid'],preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, \n",
    "                              num_workers=CFG.num_workers, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, \n",
    "                              num_workers=CFG.num_workers, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:37.418831Z",
     "iopub.status.busy": "2022-07-17T13:03:37.418099Z",
     "iopub.status.idle": "2022-07-17T13:03:37.541174Z",
     "shell.execute_reply": "2022-07-17T13:03:37.540163Z",
     "shell.execute_reply.started": "2022-07-17T13:03:37.418796Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:37.542905Z",
     "iopub.status.busy": "2022-07-17T13:03:37.542525Z",
     "iopub.status.idle": "2022-07-17T13:03:49.134106Z",
     "shell.execute_reply": "2022-07-17T13:03:49.132921Z",
     "shell.execute_reply.started": "2022-07-17T13:03:37.542868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 256, 256]), torch.Size([1, 4, 256, 256]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs, msks = next(iter(train_loader))\n",
    "imgs.size(), msks.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimiser and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.218506Z",
     "iopub.status.busy": "2022-07-17T13:03:49.217448Z",
     "iopub.status.idle": "2022-07-17T13:03:49.286893Z",
     "shell.execute_reply": "2022-07-17T13:03:49.285954Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.218466Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer):\n",
    "    if CFG.scheduler == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, ##  <---\n",
    "                                                   eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n",
    "                                                             eta_min=CFG.min_lr)\n",
    "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                   mode='min',\n",
    "                                                   factor=0.1,\n",
    "                                                   patience=7,\n",
    "                                                   threshold=0.0001,\n",
    "                                                   min_lr=CFG.min_lr,)\n",
    "    elif CFG.scheduer == 'ExponentialLR':\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
    "    elif CFG.scheduler == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.356413Z",
     "iopub.status.busy": "2022-07-17T13:03:49.353532Z",
     "iopub.status.idle": "2022-07-17T13:03:49.423352Z",
     "shell.execute_reply": "2022-07-17T13:03:49.422484Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.356386Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_optimizers(number):\n",
    "    if number == 1:\n",
    "        optimizer_1 = optim.Adam(CFG.models[0].parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
    "        CFG.optimizers = [optimizer_1]\n",
    "    return CFG.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.425106Z",
     "iopub.status.busy": "2022-07-17T13:03:49.424675Z",
     "iopub.status.idle": "2022-07-17T13:03:49.490605Z",
     "shell.execute_reply": "2022-07-17T13:03:49.489623Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.425069Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizers = build_optimizers(1)\n",
    "scheduler =  fetch_scheduler(CFG.optimizers[0])# None # Decrease LR when needed, useless with  Adam (has adaptive LR) optimizer_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚅 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.494403Z",
     "iopub.status.busy": "2022-07-17T13:03:49.494044Z",
     "iopub.status.idle": "2022-07-17T13:03:49.557755Z",
     "shell.execute_reply": "2022-07-17T13:03:49.556860Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.494374Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-07-17T13:03:49.625389Z",
     "iopub.status.busy": "2022-07-17T13:03:49.625121Z",
     "iopub.status.idle": "2022-07-17T13:03:49.692083Z",
     "shell.execute_reply": "2022-07-17T13:03:49.691074Z",
     "shell.execute_reply.started": "2022-07-17T13:03:49.625365Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: NVIDIA GeForce GTX 1060 6GB\n",
      "\n",
      "Epoch 1/80"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train :   0%|                       | 9/6562 [00:08<1:41:45,  1.07it/s, gpu_mem=0.27 GB, lr=0.00200, train_loss=0.0216]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m train_loader, valid_loader \u001b[38;5;241m=\u001b[39m prepare_loaders()\n\u001b[0;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m CFG\u001b[38;5;241m.\u001b[39moptimizers[ind]\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(model, optimizer, scheduler, device, num_epochs)\u001b[0m\n\u001b[0;32m     17\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect() \u001b[38;5;66;03m# garbage collector - to delete references and objects that not exist any more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m val_loss, val_scores \u001b[38;5;241m=\u001b[39m valid_one_epoch(model, valid_loader, \n\u001b[0;32m     25\u001b[0m                                          device\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mdevice, \n\u001b[0;32m     26\u001b[0m                                          epoch\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[0;32m     27\u001b[0m val_dice, val_jaccard \u001b[38;5;241m=\u001b[39m val_scores\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, scheduler, dataloader, device, epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m         loss   \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m CFG\u001b[38;5;241m.\u001b[39mn_accumulate \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m####################### BACKWARD #####################################################################  \u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m             \u001b[38;5;66;03m# Exits autocast before backward().\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m########################################################################################################\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m CFG\u001b[38;5;241m.\u001b[39mn_accumulate \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# остаток от деления это сделано верно\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         scaler\u001b[38;5;241m.\u001b[39mstep(optimizer) \u001b[38;5;66;03m#step - обновление весов модели\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not CFG.JUST_PREDICT:\n",
    "    for ind,  model in enumerate(CFG.models, start=0):\n",
    "        train_loader, valid_loader = prepare_loaders()\n",
    "        optimizer = CFG.optimizers[ind]\n",
    "        model = run_training(model, optimizer, scheduler,\n",
    "                                      device=CFG.device,\n",
    "                                      num_epochs=CFG.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
